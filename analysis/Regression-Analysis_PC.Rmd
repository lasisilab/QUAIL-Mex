---
title: "Linear Regression Analysis"
author: "Junhui He, edited by Paloma C."
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include = FALSE)
```

```{r package}
# load packages
library(mice)
library(ggplot2)
library(naniar)
library(glmnet)
```

## 1 Introduction

Our **research questions** are:

A) What variables measured using Paloma's questionnaires are good predictors of HWISE total scores?

B) What HWISE questions are good predictors of alternative water insecurity measurements, such as hours of water supply (HRS_WEEK), or type of supply (continuous or intermittent, W_WC_WI)?

C) Does water insecurity has any association with Perceived stress scores (PSS)? If so, what variables/aspects of water insecurity are driving this stress levels?


Here I repeat the analyses conducted by Junhui He, but adding and removing a few variables that could make more sense as predictors of the Total HWISE score or Total PSS score. These are the two linear regression models we run earlier:

1. HW_TOTAL ~ D_AGE + D_HH_SIZE + D_CHLD + HLTH_SMK + HLTH_CPAIN_CAT + HLTH_CDIS_CAT + SES_SC_Total

2. PSS_TOTAL ~ D_AGE + D_HH_SIZE + D_CHLD + HLTH_SMK + HLTH_CPAIN_CAT + HLTH_CDIS_CAT + SES_SC_Total

The two new linear regression models are different from the previous ones:

1. Removed HLTH_SMK, HLTH_CPAIN_CAT, and HLTH_CDIS_CAT

2. Added D_LOC_TIME, SEASON, W_WS_LOC, W_WC_WI, HRS_WEEK

3. Added HWISE_TOTAL as potential predictor of PSS

## 1.b Variable descriptions for quick reference

- D_AGE: Participants' age (18:49)
- D_CHLD: Number of children participant has birthed (0:8)
- D_HH_SIZE: Household size (2:40)
- D_LOC_TIME: For how long have you lived in this neighborhood? (1:46 years)
- HLTH_CDIS_CAT: Presence of chronic disease (1= yes, 0 = no)
- HLTH_CPAIN_CAT: Presence of chronic pain (1= yes, 0 = no)
- HLTH_SMK: Tabacco smoker (1= yes, 0 = no)
- HRS_WEEK: Hours of water supply in the household per week (0:168)
- HW_TOTAL: Sum of all 12-items in HWISE questionnaire (0:27)
- PSS_TOTAL: Total Perceived Stress Score (-19:19)
- SEASON: Fall or Spring (when data collection happened) (Fall= 1, Spring = 0)
- SES_SC_Total: Socioeconomic status score (25:263)
- W_WS_LOC: Classification of neighborhoods as water secure or insecure, according to reports from Mexico City water system (1= water insecure, 0= water secure)
- W_WC_WI: Classification of water supply as continuous or intermittent, according to participants (1= intermittent, 0 = continuous)


## 2 Data preparation

1. We remove rows with missing data.

2. HW_TOTAL is calculated by adding up all the HWISE scores; PSS_TOTAL is calculated by adding up PSS 1,2,3, 8, 11, 12, 14, and substracting 4,5,6,7,9,10, and 13.

```{r read-data}

data_path = "data"
# merged dataset
merged_dataset = read.csv(file.path(data_path, "Cleaned_Dataset_Screening_HWISE_PSS_V2.csv"), stringsAsFactors = FALSE)

for (i in 1:dim(merged_dataset)[2]) {
  merged_dataset[[i]] = as.numeric(merged_dataset[[i]])
}

# create regression dataset
reg_dataset = merged_dataset[c(1, 3:6, 8, 9, 10, 39, 40, 41)]
reg_dataset$PSS_TOTAL = rowSums(merged_dataset[(22 + c(1,2,3,8,11,12,14))]) - rowSums(merged_dataset[(22 + c(4,5,6,7,9,10,13))])

dim(reg_dataset)
# remove missing rows
reg_dataset = na.omit(reg_dataset)
dim(reg_dataset)
colnames(reg_dataset)
```

## 3 Results

### 3.1 HWISE scores, variable set 1

The regression results for HW is summarized as follows.

```{r regression-HW, include=TRUE}
HW_lm = lm(HW_TOTAL ~ D_AGE+D_HH_SIZE+D_CHLD+SES_SC_Total, data = reg_dataset)
summary(HW_lm)
```
The goodness-of-fit for HW regression is given as follow.

```{r goodness-of-fit-HW, include=TRUE}
ggplot() + geom_point(aes(reg_dataset$HW_TOTAL, HW_lm$fitted.values)) +
  geom_abline(linetype='longdash', linewidth=1) +
  xlab("Ground truth of HW_TOTAL") + 
  ylab("Fitted value") + 
  ggtitle("Goodness of Fit for HW_TOTAL", subtitle = "(Fitted value versus ground truth for HW_TOTAL)")
```
### 3.2 HWISE scores, variable set 2

```{r regression-HW-V2, include=TRUE}
HW_lm = lm(HW_TOTAL ~ D_LOC_TIME+SEASON+W_WS_LOC+W_WC_WI+HRS_WEEK+D_AGE+D_HH_SIZE+D_CHLD+SES_SC_Total, data = reg_dataset)
summary(HW_lm)
```


The goodness-of-fit for HW regression is given as follow.

```{r goodness-of-fit-HW-V2, include=TRUE}
ggplot() + geom_point(aes(reg_dataset$HW_TOTAL, HW_lm$fitted.values)) +
  geom_abline(linetype='longdash', linewidth=1) +
  xlab("Ground truth of HW_TOTAL") + 
  ylab("Fitted value") + 
  ggtitle("Goodness of Fit for HW_TOTAL", subtitle = "(Fitted value versus ground truth for HW_TOTAL)")
```

### 3.2 HWISE scores, variable set 3

```{r regression-HW-V3, include=TRUE}
HW_lm = lm(HW_TOTAL ~ SEASON+W_WS_LOC+W_WC_WI+HRS_WEEK+D_AGE+D_HH_SIZE+D_CHLD+SES_SC_Total, data = reg_dataset)
summary(HW_lm)
```

The goodness-of-fit for HW regression is given as follow.

```{r goodness-of-fit-HW-3, include=TRUE}
ggplot() + geom_point(aes(reg_dataset$HW_TOTAL, HW_lm$fitted.values)) +
  geom_abline(linetype='longdash', linewidth=1) +
  xlab("Ground truth of HW_TOTAL") + 
  ylab("Fitted value") + 
  ggtitle("Goodness of Fit for HW_TOTAL", subtitle = "(Fitted value versus ground truth for HW_TOTAL)")

```

### 3.2 HWISE scores, variable set 4

```{r regression-HW-V4, include=TRUE}
HW_lm = lm(HW_TOTAL ~ SEASON+W_WS_LOC+W_WC_WI+HRS_WEEK+D_CHLD+SES_SC_Total, data = reg_dataset)
summary(HW_lm)
```

The goodness-of-fit for HW regression is given as follow.

```{r goodness-of-fit-HW-4, include=TRUE}
ggplot() + geom_point(aes(reg_dataset$HW_TOTAL, HW_lm$fitted.values)) +
  geom_abline(linetype='longdash', linewidth=1) +
  xlab("Ground truth of HW_TOTAL") + 
  ylab("Fitted value") + 
  ggtitle("Goodness of Fit for HW_TOTAL", subtitle = "(Fitted value versus ground truth for HW_TOTAL)")

```


### 3.3 PSS

The regression results for PSS is summarized as follows.

```{r regression-PSS, include=TRUE}
PSS_lm = lm(PSS_TOTAL ~ D_LOC_TIME+SEASON+W_WS_LOC+W_WC_WI+HRS_WEEK+D_AGE+D_HH_SIZE+D_CHLD+SES_SC_Total+HW_TOTAL, data = reg_dataset)
summary(PSS_lm)
```

The goodness-of-fit for PSS regression is given as follow.


```{r goodness-of-fit-PSS, include=TRUE}
ggplot() + geom_point(aes(reg_dataset$PSS_TOTAL, PSS_lm$fitted.values)) + geom_abline(linetype='longdash', linewidth=1) + xlab("Ground truth of PSS_TOTAL") + ylab("Fitted value") + ggtitle("Goodness of Fit for PSS_TOTAL", subtitle = "(Fitted value versus ground truth for HW_TOTAL)")
```

### 3.4 Predictors for hours of water supply

WORK IN PROGRESS
I intend to add each HWISE question in these models

```{r regression-HW-V5, include=TRUE}
HW_lm = lm(HRS_WEEK ~ D_LOC_TIME+SEASON+W_WS_LOC+W_WC_WI+HW_TOTAL+D_AGE+D_HH_SIZE+D_CHLD+SES_SC_Total, data = reg_dataset)
summary(HW_lm)
```

The goodness-of-fit for HW regression is given as follow.

```{r goodness-of-fit-HW-5, include=TRUE}
ggplot() + geom_point(aes(reg_dataset$HW_TOTAL, HW_lm$fitted.values)) +
  geom_abline(linetype='longdash', linewidth=1) +
  xlab("Ground truth of HW_TOTAL") + 
  ylab("Fitted value") + 
  ggtitle("Goodness of Fit for HW_TOTAL", subtitle = "(Fitted value versus ground truth for HW_TOTAL)")

```

### 3.5 Feature selection

Using Elastic-Net Algorithm with $\alpha=0.5$, the selected predictors for HW_TOTAL include D_LOC_TIME, D_CHILD, SES_SC_TOTAL, SEASON, W_WS_LOC, W_WC_WI, and HRS_WEEK.


```{r HW-elastic-net, include=TRUE}
x_HW = as.matrix(reg_dataset[c(2:8, 10:11)])
HW_TOTAL = c(reg_dataset$HW_TOTAL)
set.seed(123)
# Try more alphas to find the best value
alpha_1 = 0.5
cv_HW_net = cv.glmnet(x_HW, HW_TOTAL, alpha = alpha_1) # 10-fold cross validation
# cv_HW_net$lambda.min
HW_final_model = glmnet(x_HW, HW_TOTAL, alpha = alpha_1, lambda = cv_HW_net$lambda.min)
 coef(HW_final_model)
```


```{r PSS-elastic-net}
x_PSS = as.matrix(reg_dataset[c(2:11)])
PSS_TOTAL = c(reg_dataset$PSS_TOTAL)
set.seed(123)
# Try more alphas to find the best value
alpha_2 = 0.5
cv_PSS_net = cv.glmnet(x_PSS, PSS_TOTAL, alpha = alpha_2) # 10-fold cross validation
PSS_final_model = glmnet(x_PSS, PSS_TOTAL, alpha = alpha_2, lambda = cv_PSS_net$lambda.min)
 coef(PSS_final_model)
```

## 4 Discussion

### 4.1 Comments on results

1. Unfortunately, the coefficient estimates are not significant except for a few predictors. This indicates the linear dependency between the response (HW_TOTAL or PSS_TOTAL) and the predictors are not significant.

2. Based on the goodness-of-fit figures, the predictive performance is really bad, which is consistent with the last comment.

### 4.2 Questions

1. Is it reasonable to use HW_TOTAL or PSS_TOTAL as response variables and other aforementioned variables as predictors? If not, how should I choose response variables and predictors?

2. Previously, I mentioned feature selection, a method used to identify the most influential variables among a set of predictors. Here, "the most influential variable" refers to one that has a significant impact on the response. However, since your cleaned dataset contains only eight predictors, I believe feature selection is unnecessary. Moreover, feature selection is typically employed to prevent overfitting, whereas our primary problem is underfitting.
